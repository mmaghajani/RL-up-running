{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN_Pong.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNv1BONhmBoIe3c2+UUNdT2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmaghajani/RL-up-running/blob/main/DQN_Pong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIFGZGyX4SDP"
      },
      "source": [
        "## Pong Game using Deep-Q Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U3oLs4j4XJ6"
      },
      "source": [
        "import gym\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zT_JjkR5JH4"
      },
      "source": [
        "### Prepare Env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og3dpM-25M4H",
        "outputId": "297141b3-558a-4a56-c82b-ec9d144478f7"
      },
      "source": [
        "!wget 'http://www.atarimania.com/roms/Roms.rar'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-16 10:24:41--  http://www.atarimania.com/roms/Roms.rar\n",
            "Resolving www.atarimania.com (www.atarimania.com)... 195.154.81.199\n",
            "Connecting to www.atarimania.com (www.atarimania.com)|195.154.81.199|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11128004 (11M) [application/x-rar-compressed]\n",
            "Saving to: ‘Roms.rar’\n",
            "\n",
            "Roms.rar            100%[===================>]  10.61M   816KB/s    in 14s     \n",
            "\n",
            "2021-09-16 10:24:55 (787 KB/s) - ‘Roms.rar’ saved [11128004/11128004]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vghqrtVE5Ujy",
        "outputId": "c28aae8a-45e0-427f-c2a0-4ce8d2e327c1"
      },
      "source": [
        "!mkdir roms\n",
        "!unrar x -r Roms.rar roms"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from Roms.rar\n",
            "\n",
            "Extracting  roms/HC ROMS.zip                                             \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  roms/ROMS.zip                                                \b\b\b\b 74%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar4Xur1V554r",
        "outputId": "c1589558-f318-45ff-a273-f5afb963f537"
      },
      "source": [
        "!python -m atari_py.import_roms roms"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copying adventure.bin from ROMS/Adventure (1980) (Atari, Warren Robinett) (CX2613, CX2613P) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/adventure.bin\n",
            "copying air_raid.bin from ROMS/Air Raid (Men-A-Vision) (PAL) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/air_raid.bin\n",
            "copying alien.bin from ROMS/Alien (1982) (20th Century Fox Video Games, Douglas 'Dallas North' Neubauer) (11006) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/alien.bin\n",
            "copying amidar.bin from ROMS/Amidar (1982) (Parker Brothers, Ed Temple) (PB5310) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/amidar.bin\n",
            "copying assault.bin from ROMS/Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/assault.bin\n",
            "copying asterix.bin from ROMS/Asterix (AKA Taz) (07-27-1983) (Atari, Jerome Domurat, Steve Woita) (CX2696) (Prototype).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asterix.bin\n",
            "copying asteroids.bin from ROMS/Asteroids (1981) (Atari, Brad Stewart - Sears) (CX2649 - 49-75163) [no copyright] ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asteroids.bin\n",
            "copying atlantis.bin from ROMS/Atlantis (Lost City of Atlantis) (1982) (Imagic, Dennis Koble) (720103-1A, 720103-1B, IA3203, IX-010-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/atlantis.bin\n",
            "copying bank_heist.bin from ROMS/Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983) (20th Century Fox Video Games, Bill Aspromonte) (11012) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bank_heist.bin\n",
            "copying battle_zone.bin from ROMS/Battlezone (1983) (Atari - GCC, Mike Feinstein, Brad Rice) (CX2681) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/battle_zone.bin\n",
            "copying beam_rider.bin from ROMS/Beamrider (1984) (Activision - Cheshire Engineering, David Rolfe, Larry Zwick) (AZ-037-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/beam_rider.bin\n",
            "copying berzerk.bin from ROMS/Berzerk (1982) (Atari, Dan Hitchens - Sears) (CX2650 - 49-75168) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/berzerk.bin\n",
            "copying bowling.bin from ROMS/Bowling (1979) (Atari, Larry Kaplan - Sears) (CX2628 - 6-99842, 49-75117) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bowling.bin\n",
            "copying boxing.bin from ROMS/Boxing - La Boxe (1980) (Activision, Bob Whitehead) (AG-002, CAG-002, AG-002-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/boxing.bin\n",
            "copying breakout.bin from ROMS/Breakout - Breakaway IV (Paddle) (1978) (Atari, Brad Stewart - Sears) (CX2622 - 6-99813, 49-75107) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/breakout.bin\n",
            "copying carnival.bin from ROMS/Carnival (1982) (Coleco - Woodside Design Associates, Steve 'Jessica Stevens' Kitchen) (2468) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/carnival.bin\n",
            "copying centipede.bin from ROMS/Centipede (1983) (Atari - GCC) (CX2676) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/centipede.bin\n",
            "copying chopper_command.bin from ROMS/Chopper Command (1982) (Activision, Bob Whitehead) (AX-015, AX-015-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/chopper_command.bin\n",
            "copying crazy_climber.bin from ROMS/Crazy Climber (1983) (Atari - Roklan, Joe Gaucher, Alex Leavens) (CX2683) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/crazy_climber.bin\n",
            "copying defender.bin from ROMS/Defender (1982) (Atari, Robert C. Polaro, Alan J. Murphy - Sears) (CX2609 - 49-75186) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/defender.bin\n",
            "copying demon_attack.bin from ROMS/Demon Attack (Death from Above) (1982) (Imagic, Rob Fulop) (720000-200, 720101-1B, 720101-1C, IA3200, IA3200C, IX-006-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/demon_attack.bin\n",
            "copying donkey_kong.bin from ROMS/Donkey Kong (1982) (Coleco - Woodside Design Associates - Imaginative Systems Software, Garry Kitchen) (2451) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/donkey_kong.bin\n",
            "copying double_dunk.bin from ROMS/Double Dunk (Super Basketball) (1989) (Atari, Matthew L. Hubbard) (CX26159) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/double_dunk.bin\n",
            "copying elevator_action.bin from ROMS/Elevator Action (1983) (Atari, Dan Hitchens) (CX26126) (Prototype) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/elevator_action.bin\n",
            "copying enduro.bin from ROMS/Enduro (1983) (Activision, Larry Miller) (AX-026, AX-026-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/enduro.bin\n",
            "copying fishing_derby.bin from ROMS/Fishing Derby (1980) (Activision, David Crane) (AG-004) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/fishing_derby.bin\n",
            "copying freeway.bin from ROMS/Freeway (1981) (Activision, David Crane) (AG-009, AG-009-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/freeway.bin\n",
            "copying frogger.bin from ROMS/Frogger (1982) (Parker Brothers, Ed English, David Lamkins) (PB5300) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frogger.bin\n",
            "copying frostbite.bin from ROMS/Frostbite (1983) (Activision, Steve Cartwright) (AX-031) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frostbite.bin\n",
            "copying galaxian.bin from ROMS/Galaxian (1983) (Atari - GCC, Mark Ackerman, Tom Calderwood, Glenn Parker) (CX2684) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/galaxian.bin\n",
            "copying gopher.bin from ROMS/Gopher (Gopher Attack) (1982) (U.S. Games Corporation - JWDA, Sylvia Day, Todd Marshall, Robin McDaniel, Henry Will IV) (VC2001) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gopher.bin\n",
            "copying gravitar.bin from ROMS/Gravitar (1983) (Atari, Dan Hitchens, Mimi Nyden) (CX2685) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gravitar.bin\n",
            "copying hero.bin from ROMS/H.E.R.O. (1984) (Activision, John Van Ryzin) (AZ-036-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/hero.bin\n",
            "copying ice_hockey.bin from ROMS/Ice Hockey - Le Hockey Sur Glace (1981) (Activision, Alan Miller) (AX-012, CAX-012, AX-012-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ice_hockey.bin\n",
            "copying jamesbond.bin from ROMS/James Bond 007 (James Bond Agent 007) (1984) (Parker Brothers - On-Time Software, Joe Gaucher, Louis Marbel) (PB5110) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/jamesbond.bin\n",
            "copying journey_escape.bin from ROMS/Journey Escape (1983) (Data Age, J. Ray Dettling) (112-006) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/journey_escape.bin\n",
            "copying kaboom.bin from ROMS/Kaboom! (Paddle) (1981) (Activision, Larry Kaplan, David Crane) (AG-010, AG-010-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kaboom.bin\n",
            "copying kangaroo.bin from ROMS/Kangaroo (1983) (Atari - GCC, Kevin Osborn) (CX2689) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kangaroo.bin\n",
            "copying keystone_kapers.bin from ROMS/Keystone Kapers - Raueber und Gendarm (1983) (Activision, Garry Kitchen - Ariola) (EAX-025, EAX-025-04I - 711 025-725) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/keystone_kapers.bin\n",
            "copying king_kong.bin from ROMS/King Kong (1982) (Tigervision - Software Electronics Corporation, Karl T. Olinger - Teldec) (7-001 - 3.60001 VE) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/king_kong.bin\n",
            "copying koolaid.bin from ROMS/Kool-Aid Man (Kool Aid Pitcher Man) (1983) (M Network, Stephen Tatsumi, Jane Terjung - Kool Aid) (MT4648) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/koolaid.bin\n",
            "copying krull.bin from ROMS/Krull (1983) (Atari, Jerome Domurat, Dave Staugas) (CX2682) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/krull.bin\n",
            "copying kung_fu_master.bin from ROMS/Kung-Fu Master (1987) (Activision - Imagineering, Dan Kitchen, Garry Kitchen) (AG-039-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kung_fu_master.bin\n",
            "copying laser_gates.bin from ROMS/Laser Gates (AKA Innerspace) (1983) (Imagic, Dan Oliver) (720118-2A, 13208, EIX-007-04I) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/laser_gates.bin\n",
            "copying lost_luggage.bin from ROMS/Lost Luggage (Airport Mayhem) (1982) (Apollo - Games by Apollo, Larry Minor, Ernie Runyon, Ed Salvo) (AP-2004) [no opening scene] ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/lost_luggage.bin\n",
            "copying montezuma_revenge.bin from ROMS/Montezuma's Revenge - Featuring Panama Joe (1984) (Parker Brothers - JWDA, Henry Will IV) (PB5760) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/montezuma_revenge.bin\n",
            "copying mr_do.bin from ROMS/Mr. Do! (1983) (CBS Electronics, Ed English) (4L4478) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/mr_do.bin\n",
            "copying ms_pacman.bin from ROMS/Ms. Pac-Man (1983) (Atari - GCC, Mark Ackerman, Glenn Parker) (CX2675) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ms_pacman.bin\n",
            "copying name_this_game.bin from ROMS/Name This Game (Guardians of Treasure) (1983) (U.S. Games Corporation - JWDA, Roger Booth, Sylvia Day, Ron Dubren, Todd Marshall, Robin McDaniel, Wes Trager, Henry Will IV) (VC1007) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/name_this_game.bin\n",
            "copying pacman.bin from ROMS/Pac-Man (1982) (Atari, Tod Frye) (CX2646) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pacman.bin\n",
            "copying phoenix.bin from ROMS/Phoenix (1983) (Atari - GCC, Mike Feinstein, John Mracek) (CX2673) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/phoenix.bin\n",
            "copying video_pinball.bin from ROMS/Pinball (AKA Video Pinball) (Zellers).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/video_pinball.bin\n",
            "copying pitfall.bin from ROMS/Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982) (Activision, David Crane) (AX-018, AX-018-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pitfall.bin\n",
            "copying pooyan.bin from ROMS/Pooyan (1983) (Konami) (RC 100-X 02) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pooyan.bin\n",
            "copying private_eye.bin from ROMS/Private Eye (1984) (Activision, Bob Whitehead) (AG-034-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/private_eye.bin\n",
            "copying qbert.bin from ROMS/Q-bert (1983) (Parker Brothers - Western Technologies, Dave Hampton, Tom Sloper) (PB5360) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/qbert.bin\n",
            "copying riverraid.bin from ROMS/River Raid (1982) (Activision, Carol Shaw) (AX-020, AX-020-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/riverraid.bin\n",
            "copying road_runner.bin from patched version of ROMS/Road Runner (1989) (Atari - Bobco, Robert C. Polaro) (CX2663) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/road_runner.bin\n",
            "copying robotank.bin from ROMS/Robot Tank (Robotank) (1983) (Activision, Alan Miller) (AZ-028, AG-028-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/robotank.bin\n",
            "copying seaquest.bin from ROMS/Seaquest (1983) (Activision, Steve Cartwright) (AX-022) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/seaquest.bin\n",
            "copying sir_lancelot.bin from ROMS/Sir Lancelot (1983) (Xonox - K-Tel Software - Product Guild, Anthony R. Henderson) (99006, 6220) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/sir_lancelot.bin\n",
            "copying skiing.bin from ROMS/Skiing - Le Ski (1980) (Activision, Bob Whitehead) (AG-005, CAG-005, AG-005-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/skiing.bin\n",
            "copying solaris.bin from ROMS/Solaris (The Last Starfighter, Star Raiders II, Universe) (1986) (Atari, Douglas Neubauer, Mimi Nyden) (CX26136) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/solaris.bin\n",
            "copying space_invaders.bin from ROMS/Space Invaders (1980) (Atari, Richard Maurer - Sears) (CX2632 - 49-75153) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/space_invaders.bin\n",
            "copying star_gunner.bin from ROMS/Stargunner (1983) (Telesys, Alex Leavens) (1005) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/star_gunner.bin\n",
            "copying surround.bin from ROMS/Surround (32 in 1) (Bit Corporation) (R320).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/surround.bin\n",
            "copying tennis.bin from ROMS/Tennis - Le Tennis (1981) (Activision, Alan Miller) (AG-007, CAG-007) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tennis.bin\n",
            "copying time_pilot.bin from ROMS/Time Pilot (1983) (Coleco - Woodside Design Associates, Harley H. Puthuff Jr.) (2663) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/time_pilot.bin\n",
            "copying trondead.bin from ROMS/TRON - Deadly Discs (TRON Joystick) (1983) (M Network - INTV - APh Technological Consulting, Jeff Ronne, Brett Stutz) (MT5662) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/trondead.bin\n",
            "copying tutankham.bin from ROMS/Tutankham (1983) (Parker Brothers, Dave Engman, Dawn Stockbridge) (PB5340) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tutankham.bin\n",
            "copying up_n_down.bin from ROMS/Up 'n Down (1984) (SEGA - Beck-Tech, Steve Beck, Phat Ho) (009-01) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/up_n_down.bin\n",
            "copying venture.bin from ROMS/Venture (1982) (Coleco, Joseph Biel) (2457) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/venture.bin\n",
            "copying pong.bin from ROMS/Video Olympics - Pong Sports (Paddle) (1977) (Atari, Joe Decuir - Sears) (CX2621 - 99806, 6-99806, 49-75104) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pong.bin\n",
            "copying wizard_of_wor.bin from ROMS/Wizard of Wor (1982) (CBS Electronics - Roklan, Joe Hellesen, Joe Wagner) (M8774, M8794) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/wizard_of_wor.bin\n",
            "copying yars_revenge.bin from ROMS/Yars' Revenge (Time Freeze) (1982) (Atari, Howard Scott Warshaw - Sears) (CX2655 - 49-75167) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/yars_revenge.bin\n",
            "copying zaxxon.bin from ROMS/Zaxxon (1983) (Coleco) (2454) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/zaxxon.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJKoLSZ24fyH"
      },
      "source": [
        "env = gym.make('PongDeterministic-v4')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJm2NyRL6PSe"
      },
      "source": [
        "### Preprocess Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09VPZkhp6RTZ"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqmW8yf6jdM"
      },
      "source": [
        "def resize_frame(frame):\n",
        "  frame = frame[30:-12, 5:-4]\n",
        "  frame = 0.2989*frame[:,:,0] + 0.5870*frame[:,:,1] + 0.1140*frame[:,:,2]\n",
        "  frame = cv2.resize(frame,(84,84),interpolation = cv2.INTER_NEAREST)\n",
        "  frame = np.array(frame,dtype = np.uint8)\n",
        "  return frame"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "NxEzP0cR7AVH",
        "outputId": "68c1b575-b747-4fd5-a974-8e1acf3ac2a2"
      },
      "source": [
        "first_frame = env.reset()\n",
        "plt.imshow(first_frame)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff5b2358350>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "xbjnXcds7ESb",
        "outputId": "7b4a1612-5922-492d-c279-ac302240981a"
      },
      "source": [
        "plt.imshow(resize_frame(first_frame))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff5b22b7910>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TN2R6sp7dYz"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B-2CUqQOCMc"
      },
      "source": [
        "### MemoryBuffer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiWjV8foOD5j"
      },
      "source": [
        "from collections import deque\n",
        "\n",
        "class MemoryBuffer():\n",
        "  def __init__(self, max_len):\n",
        "    self.max_len = max_len\n",
        "    self.frames = deque(maxlen=max_len)\n",
        "    self.actions = deque(maxlen=max_len)\n",
        "    self.rewards = deque(maxlen=max_len)\n",
        "    self.done_flags = deque(maxlen=max_len)\n",
        "\n",
        "  def add_experience(self, frame, reward, action, is_done):\n",
        "    self.frames.append(frame)\n",
        "    self.actions.append(action)\n",
        "    self.rewards.append(reward)\n",
        "    self.done_flags.append(is_done)\n",
        "\n",
        "  def _index_valid(self,index):\n",
        "    if self.done_flags[index-3] or self.done_flags[index-2] or self.done_flags[index-1] or self.done_flags[index]:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "    \n",
        "  def sample_experinece(self, batch_size):\n",
        "    states = []\n",
        "    next_states = []\n",
        "    actions_taken = []\n",
        "    next_rewards = []\n",
        "    next_done_flags = []\n",
        "\n",
        "    while len(states) < batch_size:\n",
        "      index = np.random.randint(4,len(self.frames) - 1)\n",
        "      if self._index_valid(index):\n",
        "          state = [self.frames[index-3], self.frames[index-2], self.frames[index-1], self.frames[index]]\n",
        "          state = np.moveaxis(state,0,2)/255\n",
        "          next_state = [self.frames[index-2], self.frames[index-1], self.frames[index], self.frames[index+1]]\n",
        "          next_state = np.moveaxis(next_state,0,2)/255\n",
        "\n",
        "          states.append(state)\n",
        "          next_states.append(next_state)\n",
        "          actions_taken.append(self.actions[index])\n",
        "          next_rewards.append(self.rewards[index+1])\n",
        "          next_done_flags.append(self.done_flags[index+1])\n",
        "                        \n",
        "    return states, next_states, actions_taken, next_rewards, next_done_flags"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwR8rt36R1Zd"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY462VV-Ve3U"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, clone_model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "import tensorflow as tf"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSXLoT6eR3QB"
      },
      "source": [
        "class Agent():\n",
        "  def __init__(\n",
        "    self, \n",
        "    possible_actions, \n",
        "    starting_mem_length, \n",
        "    max_mem_length, \n",
        "    learning_rate,\n",
        "    q_eval_model_file,\n",
        "    q_target_model_file, \n",
        "    debug=False,\n",
        "    starting_epsilon=1,\n",
        "    end_epsilon=0.05,\n",
        "    gamma=0.95,\n",
        "    epsilon_decay=0.0000009,\n",
        "  ):\n",
        "    self.memory_buffer = MemoryBuffer(max_mem_length)\n",
        "    self.possible_actions = possible_actions\n",
        "    self.epsilon = starting_epsilon\n",
        "    self.epsilon_decay = epsilon_decay\n",
        "    self.epsilon_min = end_epsilon\n",
        "    self.gamma = gamma\n",
        "    self.learning_rate = learning_rate\n",
        "    self.q_eval = self._build_model()\n",
        "    self.q_target = clone_model(self.q_eval)\n",
        "    self.total_steps = 0\n",
        "    self.starting_mem_length = starting_mem_length\n",
        "    self.q_eval_model_file = q_eval_model_file\n",
        "    self.q_target_model_file = q_target_model_file\n",
        "  \n",
        "  def _build_model(self):\n",
        "    model = Sequential([\n",
        "      Input((84,84,4)),\n",
        "      Conv2D(\n",
        "          filters=32,\n",
        "          kernel_size=(8,8),\n",
        "          strides=4,\n",
        "          data_format=\"channels_last\", \n",
        "          activation='relu',\n",
        "          kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2)\n",
        "      ),\n",
        "      Conv2D(\n",
        "          filters=64,\n",
        "          kernel_size=(4,4),\n",
        "          strides=2,\n",
        "          data_format=\"channels_last\", \n",
        "          activation='relu',\n",
        "          kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2)\n",
        "      ),\n",
        "      Conv2D(\n",
        "          filters=64,\n",
        "          kernel_size=(3,3),\n",
        "          strides=1,\n",
        "          data_format=\"channels_last\", \n",
        "          activation='relu',\n",
        "          kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2)\n",
        "      ),\n",
        "      Flatten(),\n",
        "      Dense(\n",
        "          units=512,\n",
        "          activation='relu', \n",
        "          kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2)\n",
        "      ),\n",
        "      Dense(\n",
        "          units=len(self.possible_actions), \n",
        "          activation='linear'\n",
        "      ),\n",
        "    ])\n",
        "\n",
        "    optimizer = Adam(self.learning_rate)\n",
        "    model.compile(optimizer, loss=tf.keras.losses.Huber())\n",
        "    \n",
        "    model.summary()\n",
        "    print('\\nAgent Initialized\\n')\n",
        "    \n",
        "    return model\n",
        "\n",
        "  def choose_action(self, frame):\n",
        "    if np.random.rand() < self.epsilon:\n",
        "      return random.sample(self.possible_actions, 1)[0]\n",
        "    else:\n",
        "      state = [self.memory_buffer.frames[-3], self.memory_buffer.frames[-2], self.memory_buffer.frames[-1], frame]\n",
        "      state = np.moveaxis(state,0,2)/255 #We have to do this to get it into keras's goofy format of [batch_size,rows,columns,channels]\n",
        "      state = np.expand_dims(state,0) #^^^\n",
        "      action_index = np.argmax(self.q_eval.predict(state))\n",
        "      return self.possible_actions[action_index]\n",
        "\n",
        "  def learn(self, debug, batch_size):\n",
        "\n",
        "    states, next_states, actions_taken, rewards, done_flags = self.memory_buffer.sample_experinece(batch_size)\n",
        "\n",
        "    labels = self.q_eval.predict(np.array(states))\n",
        "    next_state_values = self.q_target.predict(np.array(next_states))\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      action = self.possible_actions.index(acitions_taken[i])\n",
        "      labels[i][action] = rewards[i] + (not done_flags[i]) * self.gamma * max(next_state_values[i])\n",
        "\n",
        "    self.q_eval.fit(np.array(states), labels, batch_size=batch_size, epochs=1, verbose=0)\n",
        "\n",
        "    if self.epsilon > self.end_epsilon:\n",
        "      self.epsilon -= self.epsilon_decay\n",
        "\n",
        "    self.learns += 1\n",
        "\n",
        "    if self.learns % 10000 == 0:\n",
        "      self.q_target.set_weights(self.q_eval.get_weights())\n",
        "      print(\"Target Model updated\")\n",
        "\n",
        "  def save_model(self):\n",
        "        self.q_eval.save(self.q_eval_model_file)\n",
        "        self.q_target.save(self.q_target_model_file)\n",
        "\n",
        "  def load_model(self):\n",
        "      self.q_eval=load_model(self.q_eval_model_file)\n",
        "      self.q_target=laod_model(self.q_target_model_file)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9v9ppjKP_sS"
      },
      "source": [
        "### Environment Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQqbLtjTP9jB"
      },
      "source": [
        "class ThePlay():\n",
        "  def __init__(self, env_name, agent):\n",
        "    self.env = gym.make(env_name)\n",
        "    self.agent = agent\n",
        "    self.env.reset()\n",
        "    \n",
        "\n",
        "  def _make_dummy_actions(self, number_of_actions=4):\n",
        "    starting_frame = resize_frame(self.env.step(0)[0])\n",
        "    dummy_action = 0\n",
        "    dummy_reward = 0\n",
        "    dummy_done = False\n",
        "    for i in range(number_of_actions):\n",
        "        self.agent.memory_buffer.add_experience(starting_frame, dummy_reward, dummy_action, dummy_done)\n",
        "\n",
        "    return starting_frame\n",
        "\n",
        "  def take_step(self, frame, debug):\n",
        "    self.agent.total_steps += 1\n",
        "    if self.agent.total_steps % 10000 == 0:\n",
        "      self.agent.save()\n",
        "      print('agent saved!')\n",
        "\n",
        "    action = self.agent.choose_action(frame)\n",
        "    next_frame, reward, is_done, info = self.env.step(action)\n",
        "    next_frame = resize_frame(next_frame)\n",
        "    self.agent.memory_buffer.add_experience(next_frame, reward, action, is_done)\n",
        "\n",
        "    if debug:\n",
        "        env.render()\n",
        "\n",
        "    if len(self.agent.memory_buffer.frames) > self.agent.starting_mem_length:\n",
        "        self.agent.learn(debug)\n",
        "\n",
        "    if is_done:\n",
        "      return reward, next_frame, True\n",
        "    else:\n",
        "      return reward, next_frame, False\n",
        "  \n",
        "  def play_episode(self, debug):\n",
        "    starting_frame = self._make_dummy_actions(number_of_actions=4)\n",
        "    done = False\n",
        "    score = 0\n",
        "    next_frame = starting_frame\n",
        "    while True:\n",
        "      reward, next_frame, done = self.take_step(next_frame, debug)\n",
        "      score += reward\n",
        "      if done:\n",
        "        break\n",
        "    \n",
        "    return score\n",
        "\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-lLdTJLtfsQ"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoaRdWV3tiIq"
      },
      "source": [
        "import time\n",
        "\n",
        "\n",
        "agent = Agent(\n",
        "    possible_actions=[0,2,3], \n",
        "    starting_mem_length=50000, \n",
        "    max_mem_length=750000, \n",
        "    learning_rate=0.0002, \n",
        "    debug=False,\n",
        "    starting_epsilon=1,\n",
        "    end_epsilon=0.05,\n",
        "    gamma=0.95,\n",
        "    epsilon_decay=0.0000009,\n",
        "    q_eval_model_file='agent.h5',\n",
        "    q_target_model_file='agent.h5',\n",
        ")\n",
        "env = ThePlay(env_name='PongDeterministic-v4', agent=agent)\n",
        "\n",
        "last_100_avg = [-21]\n",
        "scores = deque(maxlen = 100)\n",
        "max_score = -21\n",
        "\n",
        "for i in range(100000):\n",
        "  timesteps = agent.total_steps\n",
        "  timee = time.time()\n",
        "  score = env.play_episode(debug=False) # set debug to true for rendering\n",
        "  scores.append(score)\n",
        "  if score > max_score:\n",
        "      max_score = score\n",
        "\n",
        "  print('\\nEpisode: ' + str(i))\n",
        "  print('Steps: ' + str(agent.total_steps - timesteps))\n",
        "  print('Duration: ' + str(time.time() - timee))\n",
        "  print('Score: ' + str(score))\n",
        "  print('Max Score: ' + str(max_score))\n",
        "  print('Epsilon: ' + str(agent.epsilon))\n",
        "\n",
        "  if i%100==0 and i!=0:\n",
        "      last_100_avg.append(sum(scores)/len(scores))\n",
        "      plt.plot(np.arange(0,i+1,100),last_100_avg)\n",
        "      plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmUkcw9GEUSK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}